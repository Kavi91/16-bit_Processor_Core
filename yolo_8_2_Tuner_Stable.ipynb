{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kavi91/16-bit_Processor_Core/blob/main/yolo_8_2_Tuner_Stable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nc1siTRzMV8"
      },
      "outputs": [],
      "source": [
        "#pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "VZ_16HCV6ItQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import requests\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "mFiLXIud0VEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset function\n",
        "def download_file(url, save_name):\n",
        "    if not os.path.exists(save_name):\n",
        "        print(f\"Downloading file\")\n",
        "        file = requests.get(url, stream=True)\n",
        "        total_size = int(file.headers.get('content-length', 0))\n",
        "        block_size = 1024\n",
        "        progress_bar = tqdm(\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True\n",
        "        )\n",
        "        with open(os.path.join(save_name), 'wb') as f:\n",
        "            for data in file.iter_content(block_size):\n",
        "                progress_bar.update(len(data))\n",
        "                f.write(data)\n",
        "        progress_bar.close()\n",
        "    else:\n",
        "        print('File already present')\n",
        "\n",
        "download_file(\n",
        "    'https://www.dropbox.com/s/xc2890eh8ujy3cu/hituav-a-highaltitude-infrared-thermal-dataset.zip?dl=1',\n",
        "    'hituav-a-highaltitude-infrared-thermal-dataset.zip'\n",
        ")"
      ],
      "metadata": {
        "id": "7_zvmmnj0Z01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "YhMTiOUG9Yd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "B3qQ8HJJ9X7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ekyyfuLq9cZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "def create_dir(dir_name=\"dataset\"):\n",
        "  \"\"\"Creates a directory if it does not exist.\n",
        "\n",
        "  Args:\n",
        "    dir_name: The name of the directory to create.\n",
        "  \"\"\"\n",
        "  if not os.path.exists(dir_name):\n",
        "    os.makedirs(dir_name)\n",
        "    print(f\"Created directory: {dir_name}\")\n",
        "  else:\n",
        "    print(f\"Directory {dir_name} already exists.\")\n",
        "\n",
        "def unzip(zip_file=None):\n",
        "  \"\"\"Unzips a file to the specified directory.\n",
        "\n",
        "  Args:\n",
        "    zip_file: The path to the zip file to extract.\n",
        "  \"\"\"\n",
        "  if not zip_file or not os.path.isfile(zip_file):\n",
        "    print(\"File not found or invalid file path provided.\")\n",
        "    return\n",
        "\n",
        "  try:\n",
        "    create_dir()  # Create the directory before extraction\n",
        "    with zipfile.ZipFile(zip_file, 'r') as z:\n",
        "      z.extractall(\"./dataset\")\n",
        "      print(\"Extracted all files to the dataset directory.\")\n",
        "  except zipfile.BadZipFile:\n",
        "    print(\"Invalid zip file or file is corrupted.\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Unzip the provided dataset (replace with your actual file path)\n",
        "unzip('hituav-a-highaltitude-infrared-thermal-dataset.zip')\n"
      ],
      "metadata": {
        "id": "oEWG8deT00s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Override settings by directly setting them in the environment\n",
        "os.environ[\"YOLO_DATASETS_DIR\"] = \"hit-uav/images/\"\n"
      ],
      "metadata": {
        "id": "Z5AHPeHD8t4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Define the base path for WSL\n",
        "new_base_path = \"/home/kavinda/dataset/hit-uav\"\n",
        "\n",
        "# Load the YAML data\n",
        "with open(f\"{new_base_path}/dataset.yaml\", 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "# Update the paths\n",
        "data['path'] = new_base_path\n",
        "data['train'] = \"images/train\"\n",
        "data['val'] = \"images/val\"\n",
        "data['test'] = \"images/test\"\n",
        "\n",
        "# Save the updated data\n",
        "with open(f\"{new_base_path}/dataset.yaml\", 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False)\n",
        "\n",
        "print(\"YAML file updated successfully!\")\n",
        "print(yaml.dump(data, default_flow_style=False))\n"
      ],
      "metadata": {
        "id": "jmDkBvzm8tw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ttR61ucr8tc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/home/kavinda/dataset/hit-uav\"\n",
        "\n",
        "# List the contents of the dataset directory\n",
        "print(os.listdir(base_path))\n",
        "\n",
        "# List the contents of the images directory\n",
        "print(os.listdir(os.path.join(base_path, \"images\")))\n"
      ],
      "metadata": {
        "id": "mCMmT0hk_xoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters and their values\n",
        "hyperparameters = {\n",
        "    \"model\": None,  # Path to pretrained model or yaml config\n",
        "    \"data\": \"/home/kavinda/dataset/hit-uav/dataset.yaml\",\n",
        "    \"epochs\": 10,\n",
        "    \"time\": None,\n",
        "    \"patience\": 100,\n",
        "    \"batch\": 16,\n",
        "    \"imgsz\": 640,\n",
        "    \"save\": True,\n",
        "    \"save_period\": -1,\n",
        "    \"cache\": False,\n",
        "    \"device\": \"\",\n",
        "    \"workers\": 8,\n",
        "    \"project\": \"runs/train\",\n",
        "    \"name\": \"exp\",\n",
        "    \"exist_ok\": False,\n",
        "    \"pretrained\": True,\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"verbose\": False,\n",
        "    \"seed\": 0,\n",
        "    \"deterministic\": True,\n",
        "    \"single_cls\": False,\n",
        "    \"rect\": False,\n",
        "    \"cos_lr\": False,\n",
        "    \"close_mosaic\": 10,\n",
        "    \"resume\": False,\n",
        "    \"amp\": True,\n",
        "    \"fraction\": 1.0,\n",
        "    \"profile\": False,\n",
        "    \"freeze\": None,\n",
        "    \"lr0\": 0.005,\n",
        "    \"lrf\": 0.01,\n",
        "    \"momentum\": 0.9,\n",
        "    \"weight_decay\": 0.0005,\n",
        "    \"warmup_epochs\": 3.0,\n",
        "    \"warmup_momentum\": 0.8,\n",
        "    \"warmup_bias_lr\": 0.1,\n",
        "    \"box\": 7.5,\n",
        "    \"cls\": 0.5,\n",
        "    \"dfl\": 1.5,\n",
        "    \"pose\": 12.0,\n",
        "    \"kobj\": 2.0,\n",
        "    \"label_smoothing\": 0.0,\n",
        "    \"nbs\": 64,\n",
        "    \"overlap_mask\": True,\n",
        "    \"mask_ratio\": 4,\n",
        "    \"dropout\": 0.0,\n",
        "    \"val\": True,\n",
        "    \"plots\": False,\n",
        "    \"hsv_h\": 0.015,\n",
        "    \"hsv_s\": 0.7,\n",
        "    \"hsv_v\": 0.4,\n",
        "    \"degrees\": 0.0,\n",
        "    \"translate\": 0.1,\n",
        "    \"scale\": 0.5,\n",
        "    \"shear\": 0.0,\n",
        "    \"perspective\": 0.0,\n",
        "    \"flipud\": 0.0,\n",
        "    \"fliplr\": 0.5,\n",
        "    \"bgr\": 0.0,\n",
        "    \"mosaic\": 1.0,\n",
        "    \"mixup\": 0.0,\n",
        "    \"copy_paste\": 0.0,\n",
        "    \"auto_augment\": \"randaugment\",\n",
        "    \"erasing\": 0.4,\n",
        "    \"crop_fraction\": 1.0\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a DataFrame and write to an Excel file\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the file path\n",
        "file_path = 'hyperparameters.xlsx'\n",
        "\n",
        "# Check if the file exists and rename if necessary\n",
        "if os.path.exists(file_path):\n",
        "    base, extension = os.path.splitext(file_path)\n",
        "    counter = 1\n",
        "    new_file_path = f\"{base}_{counter}{extension}\"\n",
        "    while os.path.exists(new_file_path):\n",
        "        counter += 1\n",
        "        new_file_path = f\"{base}_{counter}{extension}\"\n",
        "    file_path = new_file_path\n",
        "\n",
        "df = pd.DataFrame(list(hyperparameters.items()), columns=['Hyperparameter', 'Value'])\n",
        "df.to_excel(file_path, index=False)\n",
        "\n",
        "print(f\"Excel file '{file_path}' has been created.\")\n"
      ],
      "metadata": {
        "id": "x3VGiGx5Wl-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map the hyperparameters from the previous cell\n",
        "manual_config = hyperparameters\n",
        "\n",
        "print(manual_config)\n"
      ],
      "metadata": {
        "id": "H9opgt-6VroV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import tensorboard\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('yolov8x.pt')\n",
        "\n",
        "# Print a statement indicating the configuration is not accessible\n",
        "print(\"Original Configuration is not accessible directly.\")\n",
        "\n",
        "# Set the log directory for TensorBoard\n",
        "log_dir = \"/home/kavinda/runs/logs\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# Train the model with the specified data and modified config\n",
        "# Here, we assume that the model.train() method can accept the hyperparameters directly\n",
        "\n",
        "%tensorboard --logdir runs/detect/train36\n",
        "\n",
        "model.train(\n",
        "    model=manual_config[\"model\"],\n",
        "    data=manual_config[\"data\"],\n",
        "    epochs=manual_config[\"epochs\"],\n",
        "    time=manual_config[\"time\"],\n",
        "    patience=manual_config[\"patience\"],\n",
        "    batch=manual_config[\"batch\"],\n",
        "    imgsz=manual_config[\"imgsz\"],\n",
        "    save=manual_config[\"save\"],\n",
        "    save_period=manual_config[\"save_period\"],\n",
        "    cache=manual_config[\"cache\"],\n",
        "    device=manual_config[\"device\"],\n",
        "    workers=manual_config[\"workers\"],\n",
        "    project=manual_config[\"project\"],\n",
        "    name=manual_config[\"name\"],\n",
        "    exist_ok=manual_config[\"exist_ok\"],\n",
        "    pretrained=manual_config[\"pretrained\"],\n",
        "    optimizer=manual_config[\"optimizer\"],\n",
        "    verbose=manual_config[\"verbose\"],\n",
        "    seed=manual_config[\"seed\"],\n",
        "    deterministic=manual_config[\"deterministic\"],\n",
        "    single_cls=manual_config[\"single_cls\"],\n",
        "    rect=manual_config[\"rect\"],\n",
        "    cos_lr=manual_config[\"cos_lr\"],\n",
        "    close_mosaic=manual_config[\"close_mosaic\"],\n",
        "    resume=manual_config[\"resume\"],\n",
        "    amp=manual_config[\"amp\"],\n",
        "    fraction=manual_config[\"fraction\"],\n",
        "    profile=manual_config[\"profile\"],\n",
        "    freeze=manual_config[\"freeze\"],\n",
        "    lr0=manual_config[\"lr0\"],\n",
        "    lrf=manual_config[\"lrf\"],\n",
        "    momentum=manual_config[\"momentum\"],\n",
        "    weight_decay=manual_config[\"weight_decay\"],\n",
        "    warmup_epochs=manual_config[\"warmup_epochs\"],\n",
        "    warmup_momentum=manual_config[\"warmup_momentum\"],\n",
        "    warmup_bias_lr=manual_config[\"warmup_bias_lr\"],\n",
        "    box=manual_config[\"box\"],\n",
        "    cls=manual_config[\"cls\"],\n",
        "    dfl=manual_config[\"dfl\"],\n",
        "    pose=manual_config[\"pose\"],\n",
        "    kobj=manual_config[\"kobj\"],\n",
        "    label_smoothing=manual_config[\"label_smoothing\"],\n",
        "    nbs=manual_config[\"nbs\"],\n",
        "    overlap_mask=manual_config[\"overlap_mask\"],\n",
        "    mask_ratio=manual_config[\"mask_ratio\"],\n",
        "    dropout=manual_config[\"dropout\"],\n",
        "    val=manual_config[\"val\"],\n",
        "    plots=manual_config[\"plots\"],\n",
        "    hsv_h=manual_config[\"hsv_h\"],\n",
        "    hsv_s=manual_config[\"hsv_s\"],\n",
        "    hsv_v=manual_config[\"hsv_v\"],\n",
        "    degrees=manual_config[\"degrees\"],\n",
        "    translate=manual_config[\"translate\"],\n",
        "    scale=manual_config[\"scale\"],\n",
        "    shear=manual_config[\"shear\"],\n",
        "    perspective=manual_config[\"perspective\"],\n",
        "    flipud=manual_config[\"flipud\"],\n",
        "    fliplr=manual_config[\"fliplr\"],\n",
        "    bgr=manual_config[\"bgr\"],\n",
        "    mosaic=manual_config[\"mosaic\"],\n",
        "    mixup=manual_config[\"mixup\"],\n",
        "    copy_paste=manual_config[\"copy_paste\"],\n",
        "    auto_augment=manual_config[\"auto_augment\"],\n",
        "    erasing=manual_config[\"erasing\"],\n",
        "    crop_fraction=manual_config[\"crop_fraction\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "LNexruh60DfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the video file\n",
        "input_video_path = 'DJI_20240517132340_0002_T.MP4'\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(input_video_path):\n",
        "    print(\"File found.\")\n",
        "else:\n",
        "    print(\"File not found.\")\n"
      ],
      "metadata": {
        "id": "VSX6R4g4QA7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the trained model\n",
        "best_model_path = \"runs/detect/train32/weights/best.pt\"\n",
        "best_model = YOLO(best_model_path)\n",
        "\n",
        "# Determine the device to use\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Set the model to the appropriate device\n",
        "best_model.to(device)\n",
        "\n",
        "# Define input and output video paths\n",
        "input_video_path = 'DJI_20240517133159_0004_T.MP4'\n",
        "output_video_path = \"runs/detect/results/result_1.mp4\"\n",
        "\n",
        "# Run the prediction\n",
        "results = best_model.predict(input_video_path, save=False)  # Do not save each frame individually\n",
        "\n",
        "# Open the input video to read frames\n",
        "input_video = cv2.VideoCapture(input_video_path)\n",
        "frame_width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(input_video.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # codec\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Iterate over each frame in the results and write to output video\n",
        "for result in results:\n",
        "    frame = result.orig_img  # Original image\n",
        "    boxes = result.boxes  # Get the detection boxes\n",
        "\n",
        "    if boxes is not None:\n",
        "        for box in boxes:  # Iterate over each box\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get the coordinates\n",
        "            conf = box.conf[0]  # Confidence\n",
        "            cls = box.cls[0]  # Class\n",
        "\n",
        "            label = f'{best_model.names[int(cls)]} {conf:.2f}'\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "# Release everything when job is finished\n",
        "input_video.release()\n",
        "out.release()\n",
        "\n",
        "print(\"Video processing completed.\")\n"
      ],
      "metadata": {
        "id": "W9ey1cWXOXOc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}